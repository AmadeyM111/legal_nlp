2025-12-09 19:37:25,055 - INFO - Setting up fine-tuning script...
2025-12-09 19:37:25,055 - INFO - Backend detected: cuda
2025-12-09 19:40:46,883 - INFO - Setting up fine-tuning script...
2025-12-09 19:40:46,883 - INFO - Backend detected: cuda
2025-12-09 19:40:46,884 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 19:40:46,884 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 19:40:46,884 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 19:40:46,884 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 19:40:46,884 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 19:40:49,291 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 19:40:49,291 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 19:40:49,360 - WARNING - bitsandbytes not installed, using regular model loading
2025-12-09 19:40:49,366 - ERROR - Error during fine-tuning: No package metadata was found for bitsandbytes
2025-12-09 19:48:21,518 - INFO - Setting up fine-tuning script...
2025-12-09 19:48:21,519 - INFO - Backend detected: cuda
2025-12-09 19:48:21,519 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 19:48:21,519 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 19:48:21,519 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 19:48:21,519 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 19:48:21,519 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 19:48:24,018 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 19:48:24,018 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 19:48:24,084 - WARNING - bitsandbytes not available (No module named 'bitsandbytes'), using regular model loading
2025-12-09 19:48:24,090 - ERROR - Error during fine-tuning: No package metadata was found for bitsandbytes
2025-12-09 20:09:04,087 - INFO - Setting up fine-tuning script...
2025-12-09 20:09:04,088 - INFO - Backend detected: cuda
2025-12-09 20:09:04,088 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 20:09:04,088 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 20:09:04,088 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 20:09:04,088 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 20:09:04,088 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 20:09:06,506 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 20:09:06,506 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 20:09:06,594 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 20:09:06,655 - ERROR - Error during fine-tuning: The current `device_map` had weights offloaded to the disk. Please provide an `offload_folder` for them. Alternatively, make sure you have `safetensors` installed if the model you are using offers the weights in this format.
2025-12-09 20:48:23,895 - INFO - Setting up fine-tuning script...
2025-12-09 20:48:23,895 - INFO - Backend detected: cuda
2025-12-09 20:48:23,896 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 20:48:23,896 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 20:48:23,896 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 20:48:23,896 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 20:48:23,896 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 20:48:26,397 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 20:48:26,397 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 20:48:26,469 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 20:49:41,334 - WARNING - Normal loading also failed ([Errno 28] No space left on device), trying without device_map
2025-12-09 21:48:03,556 - INFO - Setting up fine-tuning script...
2025-12-09 21:48:03,557 - INFO - Backend detected: cuda
2025-12-09 21:48:03,557 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 21:48:03,557 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 21:48:03,557 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 21:48:03,557 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 21:48:03,557 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 21:48:05,998 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 21:48:05,998 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 21:48:06,073 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 21:48:45,244 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 21:48:48,264 - INFO - Loading training data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 21:48:48,329 - INFO - Processing 2270 valid examples
2025-12-09 21:48:48,329 - INFO - Sample data keys: ['article_url', 'article_title', 'question', 'context']
2025-12-09 21:48:48,329 - INFO - Sample input (first 100 chars): Могу ли я требовать устранения нарушения моих прав собственности, если сосед самовольно установил за...
2025-12-09 21:48:48,329 - INFO - Sample output (first 100 chars): Гражданское законодательство основывается на признании равенства участников регулируемых им отношени...
2025-12-09 21:48:48,977 - ERROR - Error during fine-tuning: SFTTrainer.__init__() got an unexpected keyword argument 'dataset_text_field'
2025-12-09 22:05:11,272 - INFO - Setting up fine-tuning script...
2025-12-09 22:05:11,273 - INFO - Backend detected: cuda
2025-12-09 22:05:11,273 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 22:05:11,273 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:05:11,273 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:05:11,273 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 22:05:11,273 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:05:13,619 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 22:05:13,619 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:05:13,698 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 22:05:52,194 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 22:06:19,417 - INFO - Loading training data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:06:19,450 - INFO - Processing 2270 valid examples
2025-12-09 22:06:19,450 - INFO - Sample data keys: ['article_url', 'article_title', 'question', 'context']
2025-12-09 22:06:19,450 - INFO - Sample input (first 100 chars): Могу ли я требовать устранения нарушения моих прав собственности, если сосед самовольно установил за...
2025-12-09 22:06:19,450 - INFO - Sample output (first 100 chars): Гражданское законодательство основывается на признании равенства участников регулируемых им отношени...
2025-12-09 22:06:19,857 - ERROR - Error during fine-tuning: SFTTrainer.__init__() got an unexpected keyword argument 'dataset_text_field'
2025-12-09 22:13:33,280 - INFO - Setting up fine-tuning script...
2025-12-09 22:13:33,281 - INFO - Backend detected: cuda
2025-12-09 22:13:33,281 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 22:13:33,281 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:13:33,281 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:13:33,281 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 22:13:33,281 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:13:35,492 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 22:13:35,492 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:13:35,558 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 22:14:04,750 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 22:14:19,384 - ERROR - Error during fine-tuning: MPS backend out of memory (MPS allocated: 17.57 GiB, other allocations: 502.38 MiB, max allowed: 18.13 GiB). Tried to allocate 224.00 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).
2025-12-09 22:29:26,686 - INFO - Setting up fine-tuning script...
2025-12-09 22:29:26,687 - INFO - Backend detected: cuda
2025-12-09 22:29:26,687 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 22:29:26,687 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:29:26,687 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:29:26,687 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 22:29:26,687 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:29:28,852 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 22:29:28,852 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:29:28,918 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 22:29:57,727 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 22:30:14,814 - INFO - Loading training data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:30:14,844 - INFO - Processing 2270 valid examples
2025-12-09 22:30:14,844 - INFO - Sample data keys: ['article_url', 'article_title', 'question', 'context']
2025-12-09 22:30:14,844 - INFO - Sample input (first 100 chars): Могу ли я требовать устранения нарушения моих прав собственности, если сосед самовольно установил за...
2025-12-09 22:30:14,844 - INFO - Sample output (first 100 chars): Гражданское законодательство основывается на признании равенства участников регулируемых им отношени...
2025-12-09 22:30:15,064 - ERROR - Error during fine-tuning: SFTTrainer.__init__() got an unexpected keyword argument 'max_seq_length'
2025-12-09 22:45:27,197 - INFO - Setting up fine-tuning script...
2025-12-09 22:45:27,197 - INFO - Backend detected: cuda
2025-12-09 22:45:27,197 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 22:45:27,197 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:45:27,197 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:45:27,197 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 22:45:27,197 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:45:29,240 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 22:45:29,240 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 22:45:29,305 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 22:46:01,571 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 22:46:20,001 - INFO - Loading training data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 22:46:20,058 - INFO - Processing 2270 valid examples
2025-12-09 22:46:20,058 - INFO - Sample data keys: ['article_url', 'article_title', 'question', 'context']
2025-12-09 22:46:20,059 - INFO - Sample input (first 100 chars): Могу ли я требовать устранения нарушения моих прав собственности, если сосед самовольно установил за...
2025-12-09 22:46:20,059 - INFO - Sample output (first 100 chars): Гражданское законодательство основывается на признании равенства участников регулируемых им отношени...
2025-12-09 22:46:22,636 - INFO - Using SFTTrainer with formatting_func
2025-12-09 22:46:22,946 - ERROR - Error during fine-tuning: Trainer tried to instantiate bnb optimizer but `bitsandbytes` is not installed!
2025-12-09 23:23:11,105 - INFO - Setting up fine-tuning script...
2025-12-09 23:23:11,105 - INFO - Backend detected: cuda
2025-12-09 23:23:11,106 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 23:23:11,106 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 23:23:11,106 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 23:23:11,106 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 23:23:11,106 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 23:23:13,263 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 23:23:13,263 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 23:23:13,322 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 23:23:46,760 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 23:24:07,388 - INFO - Loading training data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 23:24:07,417 - INFO - Processing 2270 valid examples
2025-12-09 23:24:07,417 - INFO - Sample data keys: ['article_url', 'article_title', 'question', 'context']
2025-12-09 23:24:07,418 - INFO - Sample input (first 100 chars): Могу ли я требовать устранения нарушения моих прав собственности, если сосед самовольно установил за...
2025-12-09 23:24:07,418 - INFO - Sample output (first 100 chars): Гражданское законодательство основывается на признании равенства участников регулируемых им отношени...
2025-12-09 23:24:09,592 - INFO - Using SFTTrainer with formatting_func
2025-12-09 23:24:13,406 - ERROR - Error during fine-tuning: MPS backend out of memory (MPS allocated: 17.22 GiB, other allocations: 1.72 GiB, max allowed: 18.13 GiB). Tried to allocate 966.82 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).
2025-12-09 23:34:16,226 - INFO - Setting up fine-tuning script...
2025-12-09 23:34:16,226 - INFO - Backend detected: cuda
2025-12-09 23:34:16,227 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 23:34:16,227 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 23:34:16,227 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 23:34:16,227 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 23:34:16,227 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 23:34:18,262 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 23:34:18,263 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 23:34:18,321 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 23:34:45,229 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 23:34:57,835 - WARNING - MPS out of memory during prepare_model_for_kbit_training, trying alternative approach
2025-12-09 23:34:59,331 - ERROR - Error during fine-tuning: Invalid buffer size: 13.24 GiB
2025-12-09 23:55:56,864 - INFO - Setting up fine-tuning script...
2025-12-09 23:55:56,865 - INFO - Backend detected: cuda
2025-12-09 23:55:56,865 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-09 23:55:56,865 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 23:55:56,865 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 23:55:56,865 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-09 23:55:56,865 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-09 23:55:58,964 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-09 23:55:58,964 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-09 23:55:59,031 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-09 23:56:27,079 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-09 23:56:44,722 - WARNING - MPS out of memory during prepare_model_for_kbit_training, trying alternative approach
2025-12-09 23:56:47,011 - ERROR - Error during fine-tuning: Invalid buffer size: 13.24 GiB
2025-12-10 00:51:48,523 - INFO - Setting up fine-tuning script...
2025-12-10 00:51:48,523 - INFO - Для безопасного запуска с большим объемом памяти:
2025-12-10 00:51:48,523 - INFO - 1. Закройте все ненужные приложения
2025-12-10 00:51:48,523 - INFO - 2. Убедитесь, что у вас достаточно оперативной памяти
2025-12-10 00:51:48,523 - INFO - 3. Запустите с: export PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 && python this_script.py ...
2025-12-10 00:51:48,524 - INFO - Backend detected: cuda
2025-12-10 00:51:48,524 - INFO - Проект: /Users/antonamadeus/github-projects/Active/experimental
2025-12-10 00:51:48,524 - INFO - Модель: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-10 00:51:48,524 - INFO - Данные: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-10 00:51:48,524 - INFO - Сохранение: /Users/antonamadeus/github-projects/Active/experimental/models/models/saiga-legal-7b
2025-12-10 00:51:48,524 - INFO - Starting fine-tuning with model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged, data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-10 00:51:50,796 - INFO - Transformers + QLoRA (Unsloth not available)
2025-12-10 00:51:50,796 - INFO - Loading model: /Users/antonamadeus/github-projects/Active/experimental/models/saiga_mistral_7b_merged
2025-12-10 00:51:50,865 - WARNING - 4-bit loading failed (No package metadata was found for bitsandbytes), falling back to normal loading
2025-12-10 00:52:17,183 - WARNING - Some parameters are on the meta device because they were offloaded to the disk.
2025-12-10 00:52:32,456 - INFO - Loading training data: /Users/antonamadeus/github-projects/Active/experimental/data/processed/synthetic_qa_labeled.json
2025-12-10 00:52:32,520 - INFO - Dataset limited to 500 examples for memory optimization
2025-12-10 00:52:32,520 - INFO - Processing 500 valid examples
2025-12-10 00:52:32,520 - INFO - Sample data keys: ['article_url', 'article_title', 'question', 'context']
2025-12-10 00:52:32,520 - INFO - Sample input (first 10 chars): Могу ли я требовать устранения нарушения моих прав собственности, если сосед самовольно установил за...
2025-12-10 00:52:32,520 - INFO - Sample output (first 100 chars): Гражданское законодательство основывается на признании равенства участников регулируемых им отношени...
2025-12-10 00:52:33,843 - INFO - Using SFTTrainer with formatting_func
2025-12-10 00:53:11,900 - ERROR - Error during fine-tuning: MPS backend out of memory (MPS allocated: 17.50 GiB, other allocations: 544.75 MiB, max allowed: 18.13 GiB). Tried to allocate 237.83 MiB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).
