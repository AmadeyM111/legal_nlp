import json
import requests
from pathlib import Path
import re
import time

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
OLLAMA_URL = "http://localhost:11434/api/generate"
PROJECT_ROOT = Path(__file__).parent.parent.resolve()
DATA_DIR = PROJECT_ROOT / "data"

class LegalEvaluator:
    def __init__(self, model="mistral:7b-instruct"):
        self.model = model
        self.url = OLLAMA_URL
        
    def query_model(self, question, temperature=0.3):
        """–ó–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏"""
        data = {
            "model": self.model,
            "prompt": f"–í—ã - —é—Ä–∏—Å—Ç-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –†–§. –û—Ç–≤–µ—Ç—å—Ç–µ –Ω–∞ –≤–æ–ø—Ä–æ—Å: {question}",
            "stream": False,
            "options": {
                "temperature": temperature,
                "max_tokens": 500
            }
        }
        
        response = requests.post(self.url, json=data)
        if response.status_code == 200:
            return response.json()['response'].strip()
        else:
            return None
    
    def evaluate_answer(self, question, model_answer, reference_answer=""):
        """–û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º"""
        scores = {
            "relevance": 0,
            "completeness": 0,
            "accuracy": 0,
            "structure": 0
        }
        
        # –†–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å (—Å–æ–¥–µ—Ä–∂–∏—Ç –ª–∏ –æ—Ç–≤–µ—Ç –∫–ª—é—á–µ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏–∑ –≤–æ–ø—Ä–æ—Å–∞)
        question_words = set(re.findall(r'\b\w+\b', question.lower()))
        answer_words = set(re.findall(r'\b\w+\b', model_answer.lower()))
        relevance = len(question_words & answer_words) / len(question_words) if question_words else 0
        scores["relevance"] = min(relevance * 100, 100)
        
        # –ü–æ–ª–Ω–æ—Ç–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π)
        sentences = model_answer.split('.')
        completeness = min(len([s for s in sentences if len(s.strip()) > 20]) * 20, 100)
        scores["completeness"] = completeness
        
        # –¢–æ—á–Ω–æ—Å—Ç—å (–ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã)
        legal_terms = ["–∫–æ–¥–µ–∫—Å", "—Å—Ç–∞—Ç—å—è", "–∑–∞–∫–æ–Ω", "–ø—É–Ω–∫—Ç", "–ø–æ–ª–æ–∂–µ–Ω–∏–µ", "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–ø—Ä–∞–≤–æ", "–æ–±—è–∑–∞–Ω–Ω–æ—Å—Ç—å"]
        accuracy = sum(1 for term in legal_terms if term in model_answer.lower()) * 10
        scores["accuracy"] = min(accuracy, 100)
        
        # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (–Ω–∞–ª–∏—á–∏–µ –≤—Å—Ç—É–ø–ª–µ–Ω–∏—è, –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Å—Ç–∏, –∑–∞–∫–ª—é—á–µ–Ω–∏—è)
        has_intro = len(model_answer) > 50
        has_main = len(model_answer) > 150
        has_conclusion = len(model_answer) > 250
        structure = (has_intro + has_main + has_conclusion) * 33.33
        scores["structure"] = min(structure, 100)
        
        return scores
    
    def test_legal_questions(self):
        """–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –Ω–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –≤–æ–ø—Ä–æ—Å–∞—Ö"""
        test_questions = [
            {
                "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ —Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä –ø–æ –¢–ö –†–§ –∏ –∫–∞–∫–∏–µ –µ–≥–æ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —É—Å–ª–æ–≤–∏—è?",
                "category": "–¢–ö –†–§",
                "expected_keywords": ["—Ç—Ä—É–¥–æ–≤–æ–π –¥–æ–≥–æ–≤–æ—Ä", "—É—Å–ª–æ–≤–∏—è", "–¢–ö", "—Ä–∞–±–æ—Ç–Ω–∏–∫", "—Ä–∞–±–æ—Ç–æ–¥–∞—Ç–µ–ª—å"]
            },
            {
                "question": "–ö–∞–∫–∏–µ –≤–∏–¥—ã –æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç–∏ –ø—Ä–µ–¥—É—Å–º–æ—Ç—Ä–µ–Ω—ã –≤ –ì—Ä–∞–∂–¥–∞–Ω—Å–∫–æ–º –∫–æ–¥–µ–∫—Å–µ –†–§?",
                "category": "–ì–ö –†–§", 
                "expected_keywords": ["–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "–ì–ö", "–æ–±—è–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞", "–≤—Ä–µ–¥", "—É–±—ã—Ç–∫–∏"]
            },
            {
                "question": "–ß—Ç–æ —Ç–∞–∫–æ–µ –∏—Å–∫–æ–≤–∞—è –¥–∞–≤–Ω–æ—Å—Ç—å –∏ –∫–∞–∫–æ–π –µ–µ —Å—Ä–æ–∫ –ø–æ –æ–±—â–µ–º—É –ø—Ä–∞–≤–∏–ª—É?",
                "category": "–ì–ö –†–§",
                "expected_keywords": ["–∏—Å–∫–æ–≤–∞—è –¥–∞–≤–Ω–æ—Å—Ç—å", "—Å—Ä–æ–∫", "—Ç—Ä–∏ –≥–æ–¥–∞", "–æ–±—â–µ–µ –ø—Ä–∞–≤–∏–ª–æ"]
            }
        ]
        
        print("üîç –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –æ—Ç–≤–µ—Ç–æ–≤")
        print("=" * 70)
        print(f"–ú–æ–¥–µ–ª—å: {self.model}")
        print("=" * 70)
        
        results = []
        
        for i, test in enumerate(test_questions, 1):
            print(f"\nüìù –¢–µ—Å—Ç {i}: {test['category']}")
            print(f"‚ùì –í–æ–ø—Ä–æ—Å: {test['question']}")
            print("-" * 50)
            
            # –ó–∞–ø—Ä–æ—Å –∫ –º–æ–¥–µ–ª–∏
            answer = self.query_model(test['question'])
            
            if answer:
                print(f"ü§ñ –û—Ç–≤–µ—Ç –º–æ–¥–µ–ª–∏:\n{answer}\n")
                
                # –û—Ü–µ–Ω–∫–∞ –æ—Ç–≤–µ—Ç–∞
                scores = self.evaluate_answer(test['question'], answer)
                avg_score = sum(scores.values()) / len(scores)
                
                print("üìä –û—Ü–µ–Ω–∫–∞:")
                for criterion, score in scores.items():
                    print(f"   ‚Ä¢ {criterion}: {score:.1f}%")
                print(f"   üìà –°—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {avg_score:.1f}%")
                
                # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ–∂–∏–¥–∞–µ–º—ã–µ –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞
                found_keywords = [kw for kw in test['expected_keywords'] if kw.lower() in answer.lower()]
                keyword_coverage = len(found_keywords) / len(test['expected_keywords']) * 100
                
                print(f"   üîë –ù–∞–π–¥–µ–Ω–æ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {len(found_keywords)}/{len(test['expected_keywords'])} ({keyword_coverage:.1f}%)")
                print(f"   üîç –°–ª–æ–≤–∞: {', '.join(found_keywords)}")
                
                results.append({
                    "test": i,
                    "category": test['category'],
                    "question": test['question'],
                    "answer": answer,
                    "scores": scores,
                    "avg_score": avg_score,
                    "keyword_coverage": keyword_coverage
                })
            else:
                print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç –º–æ–¥–µ–ª–∏")
                results.append({
                    "test": i,
                    "category": test['category'],
                    "question": test['question'],
                    "answer": None,
                    "error": True
                })
            
            time.sleep(1)  # –ó–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –∑–∞–ø—Ä–æ—Å–∞–º–∏
        
        # –ò—Ç–æ–≥–æ–≤–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        print("\n" + "=" * 70)
        print("üìà –û–ë–©–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
        print("=" * 70)
        
        valid_results = [r for r in results if not r.get('error')]
        
        if valid_results:
            avg_scores = {
                criterion: sum(r['scores'][criterion] for r in valid_results) / len(valid_results)
                for criterion in valid_results[0]['scores']
            }
            avg_overall = sum(r['avg_score'] for r in valid_results) / len(valid_results)
            avg_keywords = sum(r['keyword_coverage'] for r in valid_results) / len(valid_results)
            
            print(f"üìä –°—Ä–µ–¥–Ω–∏–µ –æ—Ü–µ–Ω–∫–∏ –ø–æ –∫—Ä–∏—Ç–µ—Ä–∏—è–º:")
            for criterion, score in avg_scores.items():
                print(f"   ‚Ä¢ {criterion}: {score:.1f}%")
            print(f"   üéØ –û–±—â–∏–π —Å—Ä–µ–¥–Ω–∏–π –±–∞–ª–ª: {avg_overall:.1f}%")
            print(f"   üîë –°—Ä–µ–¥–Ω–µ–µ –ø–æ–∫—Ä—ã—Ç–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤: {avg_keywords:.1f}%")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        timestamp = time.strftime("%Y%m%d_%H%M%S")
        output_file = DATA_DIR / f"evaluation_results_{timestamp}.json"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump({
                "model": self.model,
                "timestamp": timestamp,
                "results": results,
                "summary": {
                    "total_tests": len(test_questions),
                    "successful_tests": len(valid_results),
                    "avg_overall_score": avg_overall if valid_results else 0,
                    "avg_keyword_coverage": avg_keywords if valid_results else 0
                }
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nüíæ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_file}")
        return results

if __name__ == "__main__":
    print("üöÄ –ó–∞–ø—É—Å–∫ –æ—Ü–µ–Ω–∫–∏ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –º–æ–¥–µ–ª–µ–π...")
    
    # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –æ—Ü–µ–Ω—â–∏–∫–∞
    evaluator = LegalEvaluator("mistral:7b-instruct")
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ
    results = evaluator.test_legal_questions()
    
    print("\n‚úÖ –û—Ü–µ–Ω–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")